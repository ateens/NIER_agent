{"text": "2025-10-24 11:08:54 - INFO     - util - Message is shutting down\n", "record": {"elapsed": {"repr": "2:15:29.651813", "seconds": 8129.651813}, "exception": null, "extra": {}, "file": {"name": "util.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/base/mcp/util.py"}, "function": "session_task", "level": {"icon": "ℹ️", "name": "INFO", "no": 20}, "line": 634, "message": "Message is shutting down", "module": "util", "name": "langflow.base.mcp.util", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 134169357908864, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:08:54.337861+00:00", "timestamp": 1761304134.337861}}}
{"text": "2025-10-24 11:08:54 - INFO     - util - Message is shutting down\n", "record": {"elapsed": {"repr": "2:15:29.649950", "seconds": 8129.64995}, "exception": null, "extra": {}, "file": {"name": "util.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/base/mcp/util.py"}, "function": "session_task", "level": {"icon": "ℹ️", "name": "INFO", "no": 20}, "line": 634, "message": "Message is shutting down", "module": "util", "name": "langflow.base.mcp.util", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 134169357908864, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:08:54.335998+00:00", "timestamp": 1761304134.335998}}}
{"text": "2025-10-24 11:08:54 - INFO     - util - Message is shutting down\n", "record": {"elapsed": {"repr": "2:15:29.648924", "seconds": 8129.648924}, "exception": null, "extra": {}, "file": {"name": "util.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/base/mcp/util.py"}, "function": "session_task", "level": {"icon": "ℹ️", "name": "INFO", "no": 20}, "line": 634, "message": "Message is shutting down", "module": "util", "name": "langflow.base.mcp.util", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 134169357908864, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:08:54.334972+00:00", "timestamp": 1761304134.334972}}}
{"text": "2025-10-24 11:08:54 - INFO     - util - Message is shutting down\n", "record": {"elapsed": {"repr": "2:15:29.650580", "seconds": 8129.65058}, "exception": null, "extra": {}, "file": {"name": "util.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/base/mcp/util.py"}, "function": "session_task", "level": {"icon": "ℹ️", "name": "INFO", "no": 20}, "line": 634, "message": "Message is shutting down", "module": "util", "name": "langflow.base.mcp.util", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 134169357908864, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:08:54.336628+00:00", "timestamp": 1761304134.336628}}}
{"text": "2025-10-24 11:08:54 - INFO     - util - Message is shutting down\n", "record": {"elapsed": {"repr": "2:15:29.651160", "seconds": 8129.65116}, "exception": null, "extra": {}, "file": {"name": "util.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/base/mcp/util.py"}, "function": "session_task", "level": {"icon": "ℹ️", "name": "INFO", "no": 20}, "line": 634, "message": "Message is shutting down", "module": "util", "name": "langflow.base.mcp.util", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 134169357908864, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:08:54.337208+00:00", "timestamp": 1761304134.337208}}}
{"text": "2025-10-24 11:09:01 - WARNING  - 79e675cb6752_change_datetime_type - Column 'created_at' has type DATETIME in table 'apikey'\n", "record": {"elapsed": {"repr": "0:00:05.224419", "seconds": 5.224419}, "exception": null, "extra": {}, "file": {"name": "79e675cb6752_change_datetime_type.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/alembic/versions/79e675cb6752_change_datetime_type.py"}, "function": "upgrade", "level": {"icon": "⚠️", "name": "WARNING", "no": 30}, "line": 44, "message": "Column 'created_at' has type DATETIME in table 'apikey'", "module": "79e675cb6752_change_datetime_type", "name": "79e675cb6752_change_datetime_type_py", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137477985617600, "name": "asyncio_0"}, "time": {"repr": "2025-10-24 11:09:01.642751+00:00", "timestamp": 1761304141.642751}}}
{"text": "2025-10-24 11:09:01 - WARNING  - 79e675cb6752_change_datetime_type - Column 'created_at' has type DATETIME in table 'variable'\n", "record": {"elapsed": {"repr": "0:00:05.226156", "seconds": 5.226156}, "exception": null, "extra": {}, "file": {"name": "79e675cb6752_change_datetime_type.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/alembic/versions/79e675cb6752_change_datetime_type.py"}, "function": "upgrade", "level": {"icon": "⚠️", "name": "WARNING", "no": 30}, "line": 61, "message": "Column 'created_at' has type DATETIME in table 'variable'", "module": "79e675cb6752_change_datetime_type", "name": "79e675cb6752_change_datetime_type_py", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137477985617600, "name": "asyncio_0"}, "time": {"repr": "2025-10-24 11:09:01.644488+00:00", "timestamp": 1761304141.644488}}}
{"text": "2025-10-24 11:09:01 - WARNING  - 79e675cb6752_change_datetime_type - Column 'updated_at' has type DATETIME in table 'variable'\n", "record": {"elapsed": {"repr": "0:00:05.226925", "seconds": 5.226925}, "exception": null, "extra": {}, "file": {"name": "79e675cb6752_change_datetime_type.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/alembic/versions/79e675cb6752_change_datetime_type.py"}, "function": "upgrade", "level": {"icon": "⚠️", "name": "WARNING", "no": 30}, "line": 73, "message": "Column 'updated_at' has type DATETIME in table 'variable'", "module": "79e675cb6752_change_datetime_type", "name": "79e675cb6752_change_datetime_type_py", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137477985617600, "name": "asyncio_0"}, "time": {"repr": "2025-10-24 11:09:01.645257+00:00", "timestamp": 1761304141.645257}}}
{"text": "2025-10-24 11:09:01 - WARNING  - 4e5980a44eaa_fix_date_times_again - Column 'created_at' has type DATETIME in table 'apikey'\n", "record": {"elapsed": {"repr": "0:00:05.228722", "seconds": 5.228722}, "exception": null, "extra": {}, "file": {"name": "4e5980a44eaa_fix_date_times_again.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/alembic/versions/4e5980a44eaa_fix_date_times_again.py"}, "function": "upgrade", "level": {"icon": "⚠️", "name": "WARNING", "no": 30}, "line": 44, "message": "Column 'created_at' has type DATETIME in table 'apikey'", "module": "4e5980a44eaa_fix_date_times_again", "name": "4e5980a44eaa_fix_date_times_again_py", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137477985617600, "name": "asyncio_0"}, "time": {"repr": "2025-10-24 11:09:01.647054+00:00", "timestamp": 1761304141.647054}}}
{"text": "2025-10-24 11:09:01 - WARNING  - 4e5980a44eaa_fix_date_times_again - Column 'created_at' has type DATETIME in table 'variable'\n", "record": {"elapsed": {"repr": "0:00:05.229733", "seconds": 5.229733}, "exception": null, "extra": {}, "file": {"name": "4e5980a44eaa_fix_date_times_again.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/alembic/versions/4e5980a44eaa_fix_date_times_again.py"}, "function": "upgrade", "level": {"icon": "⚠️", "name": "WARNING", "no": 30}, "line": 61, "message": "Column 'created_at' has type DATETIME in table 'variable'", "module": "4e5980a44eaa_fix_date_times_again", "name": "4e5980a44eaa_fix_date_times_again_py", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137477985617600, "name": "asyncio_0"}, "time": {"repr": "2025-10-24 11:09:01.648065+00:00", "timestamp": 1761304141.648065}}}
{"text": "2025-10-24 11:09:01 - WARNING  - 4e5980a44eaa_fix_date_times_again - Column 'updated_at' has type DATETIME in table 'variable'\n", "record": {"elapsed": {"repr": "0:00:05.230464", "seconds": 5.230464}, "exception": null, "extra": {}, "file": {"name": "4e5980a44eaa_fix_date_times_again.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/alembic/versions/4e5980a44eaa_fix_date_times_again.py"}, "function": "upgrade", "level": {"icon": "⚠️", "name": "WARNING", "no": 30}, "line": 73, "message": "Column 'updated_at' has type DATETIME in table 'variable'", "module": "4e5980a44eaa_fix_date_times_again", "name": "4e5980a44eaa_fix_date_times_again_py", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137477985617600, "name": "asyncio_0"}, "time": {"repr": "2025-10-24 11:09:01.648796+00:00", "timestamp": 1761304141.648796}}}
{"text": "2025-10-24 11:18:08 - ERROR    - agent - ExceptionWithMessageError: Connection error..\n", "record": {"elapsed": {"repr": "0:09:11.806127", "seconds": 551.806127}, "exception": null, "extra": {}, "file": {"name": "agent.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/base/agents/agent.py"}, "function": "run_agent", "level": {"icon": "❌", "name": "ERROR", "no": 40}, "line": 191, "message": "ExceptionWithMessageError: Connection error..", "module": "agent", "name": "langflow.base.agents.agent", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137479754177408, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:18:08.224459+00:00", "timestamp": 1761304688.224459}}}
{"text": "2025-10-24 11:18:08 - ERROR    - <string> - ExceptionWithMessageError occurred: Connection error..\n", "record": {"elapsed": {"repr": "0:09:11.807243", "seconds": 551.807243}, "exception": null, "extra": {}, "file": {"name": "<string>", "path": "<string>"}, "function": "message_response", "level": {"icon": "❌", "name": "ERROR", "no": 40}, "line": 171, "message": "ExceptionWithMessageError occurred: Connection error..", "module": "<string>", "name": "langflow.utils.validate", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137479754177408, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:18:08.225575+00:00", "timestamp": 1761304688.225575}}}
{"text": "2025-10-24 11:18:08 - ERROR    - base - Connection error..\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n    yield\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n                 |    |     |                    -> <Request [b'POST']>\n                 |    |     -> <function AsyncConnectionPool.handle_async_request at 0x7d097e18f7e0>\n                 |    -> <AsyncConnectionPool [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>\n                 -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 211, in handle_async_request\n    raise UnsupportedProtocol(\n          -> <class 'httpcore.UnsupportedProtocol'>\n\nhttpcore.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1500, in _request\n    response = await self._client.send(\n                     |    |       -> <function AsyncClient.send at 0x7d097e1bf240>\n                     |    -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n                     -> <openai.AsyncOpenAI object at 0x7d08b84c75c0>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1674, in send\n    response = await self._send_handling_auth(\n                     |    -> <function AsyncClient._send_handling_auth at 0x7d097e1bf2e0>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n    response = await self._send_handling_redirects(\n                     |    -> <function AsyncClient._send_handling_redirects at 0x7d097e1bf380>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n    response = await self._send_single_request(request)\n                     |    |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |    -> <function AsyncClient._send_single_request at 0x7d097e1bf420>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n    response = await transport.handle_async_request(request)\n                     |         |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |         -> <function AsyncHTTPTransport.handle_async_request at 0x7d097e1bc360>\n                     -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 376, in handle_async_request\n    with map_httpcore_exceptions():\n         -> <function map_httpcore_exceptions at 0x7d097ed46520>\n  File \"/usr/local/lib/python3.12/contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n    |    |   |     -> UnsupportedProtocol(\"Request URL has an unsupported protocol 'htp://'.\")\n    |    |   -> <method 'throw' of 'generator' objects>\n    |    -> <generator object map_httpcore_exceptions at 0x7d08cc31a740>\n    -> <contextlib._GeneratorContextManager object at 0x7d09188a4890>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\n          |          -> \"Request URL has an unsupported protocol 'htp://'.\"\n          -> <class 'httpx.UnsupportedProtocol'>\n\nhttpx.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n    yield\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n                 |    |     |                    -> <Request [b'POST']>\n                 |    |     -> <function AsyncConnectionPool.handle_async_request at 0x7d097e18f7e0>\n                 |    -> <AsyncConnectionPool [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>\n                 -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 211, in handle_async_request\n    raise UnsupportedProtocol(\n          -> <class 'httpcore.UnsupportedProtocol'>\n\nhttpcore.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1500, in _request\n    response = await self._client.send(\n                     |    |       -> <function AsyncClient.send at 0x7d097e1bf240>\n                     |    -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n                     -> <openai.AsyncOpenAI object at 0x7d08b84c75c0>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1674, in send\n    response = await self._send_handling_auth(\n                     |    -> <function AsyncClient._send_handling_auth at 0x7d097e1bf2e0>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n    response = await self._send_handling_redirects(\n                     |    -> <function AsyncClient._send_handling_redirects at 0x7d097e1bf380>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n    response = await self._send_single_request(request)\n                     |    |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |    -> <function AsyncClient._send_single_request at 0x7d097e1bf420>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n    response = await transport.handle_async_request(request)\n                     |         |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |         -> <function AsyncHTTPTransport.handle_async_request at 0x7d097e1bc360>\n                     -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 376, in handle_async_request\n    with map_httpcore_exceptions():\n         -> <function map_httpcore_exceptions at 0x7d097ed46520>\n  File \"/usr/local/lib/python3.12/contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n    |    |   |     -> UnsupportedProtocol(\"Request URL has an unsupported protocol 'htp://'.\")\n    |    |   -> <method 'throw' of 'generator' objects>\n    |    -> <generator object map_httpcore_exceptions at 0x7d0918a68240>\n    -> <contextlib._GeneratorContextManager object at 0x7d08b851c170>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\n          |          -> \"Request URL has an unsupported protocol 'htp://'.\"\n          -> <class 'httpx.UnsupportedProtocol'>\n\nhttpx.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n    yield\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n                 |    |     |                    -> <Request [b'POST']>\n                 |    |     -> <function AsyncConnectionPool.handle_async_request at 0x7d097e18f7e0>\n                 |    -> <AsyncConnectionPool [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>\n                 -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 211, in handle_async_request\n    raise UnsupportedProtocol(\n          -> <class 'httpcore.UnsupportedProtocol'>\n\nhttpcore.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1500, in _request\n    response = await self._client.send(\n                     |    |       -> <function AsyncClient.send at 0x7d097e1bf240>\n                     |    -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n                     -> <openai.AsyncOpenAI object at 0x7d08b84c75c0>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1674, in send\n    response = await self._send_handling_auth(\n                     |    -> <function AsyncClient._send_handling_auth at 0x7d097e1bf2e0>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n    response = await self._send_handling_redirects(\n                     |    -> <function AsyncClient._send_handling_redirects at 0x7d097e1bf380>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n    response = await self._send_single_request(request)\n                     |    |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |    -> <function AsyncClient._send_single_request at 0x7d097e1bf420>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n    response = await transport.handle_async_request(request)\n                     |         |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |         -> <function AsyncHTTPTransport.handle_async_request at 0x7d097e1bc360>\n                     -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 376, in handle_async_request\n    with map_httpcore_exceptions():\n         -> <function map_httpcore_exceptions at 0x7d097ed46520>\n  File \"/usr/local/lib/python3.12/contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n    |    |   |     -> UnsupportedProtocol(\"Request URL has an unsupported protocol 'htp://'.\")\n    |    |   -> <method 'throw' of 'generator' objects>\n    |    -> <generator object map_httpcore_exceptions at 0x7d08cc31a140>\n    -> <contextlib._GeneratorContextManager object at 0x7d09188a6e40>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\n          |          -> \"Request URL has an unsupported protocol 'htp://'.\"\n          -> <class 'httpx.UnsupportedProtocol'>\n\nhttpx.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n    yield\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n                 |    |     |                    -> <Request [b'POST']>\n                 |    |     -> <function AsyncConnectionPool.handle_async_request at 0x7d097e18f7e0>\n                 |    -> <AsyncConnectionPool [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>\n                 -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 211, in handle_async_request\n    raise UnsupportedProtocol(\n          -> <class 'httpcore.UnsupportedProtocol'>\n\nhttpcore.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1500, in _request\n    response = await self._client.send(\n                     |    |       -> <function AsyncClient.send at 0x7d097e1bf240>\n                     |    -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n                     -> <openai.AsyncOpenAI object at 0x7d08b84c75c0>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1674, in send\n    response = await self._send_handling_auth(\n                     |    -> <function AsyncClient._send_handling_auth at 0x7d097e1bf2e0>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n    response = await self._send_handling_redirects(\n                     |    -> <function AsyncClient._send_handling_redirects at 0x7d097e1bf380>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n    response = await self._send_single_request(request)\n                     |    |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |    -> <function AsyncClient._send_single_request at 0x7d097e1bf420>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n    response = await transport.handle_async_request(request)\n                     |         |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |         -> <function AsyncHTTPTransport.handle_async_request at 0x7d097e1bc360>\n                     -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 376, in handle_async_request\n    with map_httpcore_exceptions():\n         -> <function map_httpcore_exceptions at 0x7d097ed46520>\n  File \"/usr/local/lib/python3.12/contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n    |    |   |     -> UnsupportedProtocol(\"Request URL has an unsupported protocol 'htp://'.\")\n    |    |   -> <method 'throw' of 'generator' objects>\n    |    -> <generator object map_httpcore_exceptions at 0x7d08cc31ba40>\n    -> <contextlib._GeneratorContextManager object at 0x7d09188a52e0>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\n          |          -> \"Request URL has an unsupported protocol 'htp://'.\"\n          -> <class 'httpx.UnsupportedProtocol'>\n\nhttpx.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n    yield\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n                 |    |     |                    -> <Request [b'POST']>\n                 |    |     -> <function AsyncConnectionPool.handle_async_request at 0x7d097e18f7e0>\n                 |    -> <AsyncConnectionPool [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>\n                 -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 211, in handle_async_request\n    raise UnsupportedProtocol(\n          -> <class 'httpcore.UnsupportedProtocol'>\n\nhttpcore.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1500, in _request\n    response = await self._client.send(\n                     |    |       -> <function AsyncClient.send at 0x7d097e1bf240>\n                     |    -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n                     -> <openai.AsyncOpenAI object at 0x7d08b84c75c0>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1674, in send\n    response = await self._send_handling_auth(\n                     |    -> <function AsyncClient._send_handling_auth at 0x7d097e1bf2e0>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n    response = await self._send_handling_redirects(\n                     |    -> <function AsyncClient._send_handling_redirects at 0x7d097e1bf380>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n    response = await self._send_single_request(request)\n                     |    |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |    -> <function AsyncClient._send_single_request at 0x7d097e1bf420>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n    response = await transport.handle_async_request(request)\n                     |         |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |         -> <function AsyncHTTPTransport.handle_async_request at 0x7d097e1bc360>\n                     -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 376, in handle_async_request\n    with map_httpcore_exceptions():\n         -> <function map_httpcore_exceptions at 0x7d097ed46520>\n  File \"/usr/local/lib/python3.12/contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n    |    |   |     -> UnsupportedProtocol(\"Request URL has an unsupported protocol 'htp://'.\")\n    |    |   -> <method 'throw' of 'generator' objects>\n    |    -> <generator object map_httpcore_exceptions at 0x7d0918af7940>\n    -> <contextlib._GeneratorContextManager object at 0x7d09188a6c00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\n          |          -> \"Request URL has an unsupported protocol 'htp://'.\"\n          -> <class 'httpx.UnsupportedProtocol'>\n\nhttpx.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n    yield\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n                 |    |     |                    -> <Request [b'POST']>\n                 |    |     -> <function AsyncConnectionPool.handle_async_request at 0x7d097e18f7e0>\n                 |    -> <AsyncConnectionPool [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>\n                 -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 211, in handle_async_request\n    raise UnsupportedProtocol(\n          -> <class 'httpcore.UnsupportedProtocol'>\n\nhttpcore.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1500, in _request\n    response = await self._client.send(\n                     |    |       -> <function AsyncClient.send at 0x7d097e1bf240>\n                     |    -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n                     -> <openai.AsyncOpenAI object at 0x7d08b84c75c0>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1674, in send\n    response = await self._send_handling_auth(\n                     |    -> <function AsyncClient._send_handling_auth at 0x7d097e1bf2e0>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n    response = await self._send_handling_redirects(\n                     |    -> <function AsyncClient._send_handling_redirects at 0x7d097e1bf380>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n    response = await self._send_single_request(request)\n                     |    |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |    -> <function AsyncClient._send_single_request at 0x7d097e1bf420>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n    response = await transport.handle_async_request(request)\n                     |         |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |         -> <function AsyncHTTPTransport.handle_async_request at 0x7d097e1bc360>\n                     -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 376, in handle_async_request\n    with map_httpcore_exceptions():\n         -> <function map_httpcore_exceptions at 0x7d097ed46520>\n  File \"/usr/local/lib/python3.12/contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n    |    |   |     -> UnsupportedProtocol(\"Request URL has an unsupported protocol 'htp://'.\")\n    |    |   -> <method 'throw' of 'generator' objects>\n    |    -> <generator object map_httpcore_exceptions at 0x7d0918af7740>\n    -> <contextlib._GeneratorContextManager object at 0x7d09188a7380>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\n          |          -> \"Request URL has an unsupported protocol 'htp://'.\"\n          -> <class 'httpx.UnsupportedProtocol'>\n\nhttpx.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/base/agents/events.py\", line 334, in process_agent_events\n    async for event in agent_executor:\n              |        -> <async_generator object Runnable.astream_events at 0x7d09223df940>\n              -> {'event': 'on_chat_model_start', 'data': {'input': {'messages': [[SystemMessage(content='- 사용자의 요청에서 station_id(정수), element(...\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 1404, in astream_events\n    async for event in event_stream:\n              |        -> <async_generator object _astream_events_implementation_v2 at 0x7d08b83a8fe0>\n              -> {'event': 'on_chat_model_start', 'data': {'input': {'messages': [[SystemMessage(content='- 사용자의 요청에서 station_id(정수), element(...\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/tracers/event_stream.py\", line 1021, in _astream_events_implementation_v2\n    await task\n          -> <Task finished name='Task-1680' coro=<_astream_events_implementation_v2.<locals>.consume_astream() done, defined at /app/.ven...\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/tracers/event_stream.py\", line 976, in consume_astream\n    async for _ in event_streamer.tap_output_aiter(run_id, stream):\n                   |              |                |       -> <async_generator object AgentExecutor.astream at 0x7d08bc537be0>\n                   |              |                -> UUID('c1e3920c-e34b-42fc-817c-dfb6a555ab36')\n                   |              -> <function _AstreamEventsCallbackHandler.tap_output_aiter at 0x7d0918a59d00>\n                   -> <langchain_core.tracers.event_stream._AstreamEventsCallbackHandler object at 0x7d08b83705f0>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/tracers/event_stream.py\", line 181, in tap_output_aiter\n    first = await py_anext(output, default=sentinel)\n                  |        |               -> <object object at 0x7d0912f700c0>\n                  |        -> <async_generator object AgentExecutor.astream at 0x7d08bc537be0>\n                  -> <function py_anext at 0x7d0915b70ae0>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/utils/aiter.py\", line 78, in anext_impl\n    return await __anext__(iterator)\n                 |         -> <async_generator object AgentExecutor.astream at 0x7d08bc537be0>\n                 -> <slot wrapper '__anext__' of 'async_generator' objects>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain/agents/agent.py\", line 1805, in astream\n    async for step in iterator:\n                      -> <langchain.agents.agent_iterator.AgentExecutorIterator object at 0x7d0912d4f4d0>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain/agents/agent_iterator.py\", line 266, in __aiter__\n    async for chunk in self.agent_executor._aiter_next_step(\n                       |    -> <property object at 0x7d0913ff8900>\n                       -> <langchain.agents.agent_iterator.AgentExecutorIterator object at 0x7d0912d4f4d0>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain/agents/agent.py\", line 1495, in _aiter_next_step\n    output = await self._action_agent.aplan(\n                   |    -> <property object at 0x7d0913e977e0>\n                   -> AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n                        agent_scratchpad: RunnableLambd...\n  File \"/app/.venv/lib/python3.12/site-packages/langchain/agents/agent.py\", line 620, in aplan\n    async for chunk in self.runnable.astream(\n                       |    |        -> <function RunnableSequence.astream at 0x7d0915b958a0>\n                       |    -> RunnableAssign(mapper={\n                       |         agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n                       |       })\n                       |       | ChatPro...\n                       -> RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n                            agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['i...\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 3465, in astream\n    async for chunk in self.atransform(input_aiter(), config, **kwargs):\n                       |    |          |              |         -> {}\n                       |    |          |              -> {'callbacks': <langchain_core.callbacks.manager.AsyncCallbackManager object at 0x7d08b8371e80>}\n                       |    |          -> <function RunnableSequence.astream.<locals>.input_aiter at 0x7d0918ac7e20>\n                       |    -> <function RunnableSequence.atransform at 0x7d0915b95800>\n                       -> RunnableAssign(mapper={\n                            agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n                          })\n                          | ChatPro...\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 3447, in atransform\n    async for chunk in self._atransform_stream_with_config(\n                       |    -> <function Runnable._atransform_stream_with_config at 0x7d0915b73f60>\n                       -> RunnableAssign(mapper={\n                            agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n                          })\n                          | ChatPro...\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 2322, in _atransform_stream_with_config\n    chunk = await coro_with_context(py_anext(iterator), context)\n                  |                 |        |          -> <_contextvars.Context object at 0x7d08b8536bc0>\n                  |                 |        -> <async_generator object _AstreamEventsCallbackHandler.tap_output_aiter at 0x7d0918a4d6d0>\n                  |                 -> <function py_anext at 0x7d0915b70ae0>\n                  -> <function coro_with_context at 0x7d0915b02f20>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/tracers/event_stream.py\", line 181, in tap_output_aiter\n    first = await py_anext(output, default=sentinel)\n                  |        |               -> <object object at 0x7d0912f71e60>\n                  |        -> <async_generator object RunnableSequence._atransform at 0x7d09188174c0>\n                  -> <function py_anext at 0x7d0915b70ae0>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/utils/aiter.py\", line 78, in anext_impl\n    return await __anext__(iterator)\n                 |         -> <async_generator object RunnableSequence._atransform at 0x7d09188174c0>\n                 -> <slot wrapper '__anext__' of 'async_generator' objects>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 3414, in _atransform\n    async for output in final_pipeline:\n                        -> <async_generator object Runnable.atransform at 0x7d0913011f10>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 1471, in atransform\n    async for ichunk in input:\n                        -> <async_generator object RunnableBindingBase.atransform at 0x7d0918af5540>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 5660, in atransform\n    async for item in self.bound.atransform(\n                      |    |     -> <function Runnable.atransform at 0x7d0915b736a0>\n                      |    -> ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7d08b84c63c0>, async_client=<openai....\n                      -> RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7d08b84c63c0>,...\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 1489, in atransform\n    async for output in self.astream(final, config, **kwargs):\n                        |    |       |      |         -> {'tools': [{'type': 'function', 'function': {'name': 'get_current_date', 'description': 'Returns the current date and time in...\n                        |    |       |      -> {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.AsyncCallbackManager object at 0x7d08b851e060>, '...\n                        |    |       -> ChatPromptValue(messages=[SystemMessage(content='- 사용자의 요청에서 station_id(정수), element(대문자 성분), start_time, end_time(YYYY-MM-DD...\n                        |    -> <function BaseChatModel.astream at 0x7d09138bc900>\n                        -> ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7d08b84c63c0>, async_client=<openai....\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 592, in astream\n    async for chunk in self._astream(\n                       |    -> <function ChatOpenAI._astream at 0x7d08bbb15440>\n                       -> ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7d08b84c63c0>, async_client=<openai....\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 2497, in _astream\n    async for chunk in super()._astream(*args, **kwargs):\n                                         |       -> {'stop': None, 'tools': [{'type': 'function', 'function': {'name': 'get_current_date', 'description': 'Returns the current da...\n                                         -> ([SystemMessage(content='- 사용자의 요청에서 station_id(정수), element(대문자 성분), start_time, end_time(YYYY-MM-DD 또는 YYYY-MM-DD HH:MM:SS)...\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 1111, in _astream\n    response = await self.async_client.create(**payload)\n                     |    |            |        -> {'model': 'qwen3-30b-awq', 'stream': True, 'seed': 1, 'temperature': 0.1, 'tools': [{'type': 'function', 'function': {'name':...\n                     |    |            -> <function AsyncCompletions.create at 0x7d0910c4b2e0>\n                     |    -> <openai.resources.chat.completions.completions.AsyncCompletions object at 0x7d08b84c5880>\n                     -> ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7d08b84c63c0>, async_client=<openai....\n  File \"/app/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2000, in create\n    return await self._post(\n                 |    -> <bound method AsyncAPIClient.post of <openai.AsyncOpenAI object at 0x7d08b84c75c0>>\n                 -> <openai.resources.chat.completions.completions.AsyncCompletions object at 0x7d08b84c5880>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n                 |    |       |        |            |                  -> openai.AsyncStream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]\n                 |    |       |        |            -> True\n                 |    |       |        -> FinalRequestOptions(method='post', url='/chat/completions', params={}, headers=NOT_GIVEN, max_retries=NOT_GIVEN, timeout=NOT_...\n                 |    |       -> <class 'openai.types.chat.chat_completion.ChatCompletion'>\n                 |    -> <function AsyncAPIClient.request at 0x7d0910e9b880>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84c75c0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n                 |    -> <function AsyncAPIClient._request at 0x7d0910e9b920>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84c75c0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1524, in _request\n    return await self._retry_request(\n                 |    -> <function AsyncAPIClient._retry_request at 0x7d0910e9b9c0>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84c75c0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n                 |    -> <function AsyncAPIClient._request at 0x7d0910e9b920>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84c75c0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1524, in _request\n    return await self._retry_request(\n                 |    -> <function AsyncAPIClient._retry_request at 0x7d0910e9b9c0>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84c75c0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n                 |    -> <function AsyncAPIClient._request at 0x7d0910e9b920>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84c75c0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1524, in _request\n    return await self._retry_request(\n                 |    -> <function AsyncAPIClient._retry_request at 0x7d0910e9b9c0>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84c75c0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n                 |    -> <function AsyncAPIClient._request at 0x7d0910e9b920>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84c75c0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1524, in _request\n    return await self._retry_request(\n                 |    -> <function AsyncAPIClient._retry_request at 0x7d0910e9b9c0>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84c75c0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n                 |    -> <function AsyncAPIClient._request at 0x7d0910e9b920>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84c75c0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1524, in _request\n    return await self._retry_request(\n                 |    -> <function AsyncAPIClient._retry_request at 0x7d0910e9b9c0>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84c75c0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n                 |    -> <function AsyncAPIClient._request at 0x7d0910e9b920>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84c75c0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1534, in _request\n    raise APIConnectionError(request=request) from err\n          |                          -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n          -> <class 'openai.APIConnectionError'>\n\nopenai.APIConnectionError: Connection error.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/bin/langflow\", line 10, in <module>\n    sys.exit(main())\n    |   |    -> <function main at 0x7d097fb2e840>\n    |   -> <built-in function exit>\n    -> <module 'sys' (built-in)>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/langflow_launcher.py\", line 20, in main\n    langflow_main()\n    -> <function main at 0x7d08bbac23e0>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/__main__.py\", line 936, in main\n    app()\n    -> <typer.main.Typer object at 0x7d08bbeaf710>\n  File \"/app/.venv/lib/python3.12/site-packages/typer/main.py\", line 324, in __call__\n    return get_command(self)(*args, **kwargs)\n           |           |      |       -> {}\n           |           |      -> ()\n           |           -> <typer.main.Typer object at 0x7d08bbeaf710>\n           -> <function get_command at 0x7d097efa6840>\n  File \"/app/.venv/lib/python3.12/site-packages/click/core.py\", line 1442, in __call__\n    return self.main(*args, **kwargs)\n           |    |     |       -> {}\n           |    |     -> ()\n           |    -> <function TyperGroup.main at 0x7d097efa51c0>\n           -> <TyperGroup >\n  File \"/app/.venv/lib/python3.12/site-packages/typer/core.py\", line 757, in main\n    return _main(\n           -> <function _main at 0x7d097efa42c0>\n  File \"/app/.venv/lib/python3.12/site-packages/typer/core.py\", line 195, in _main\n    rv = self.invoke(ctx)\n         |    |      -> <click.core.Context object at 0x7d08bbd562a0>\n         |    -> <function Group.invoke at 0x7d097f93e8e0>\n         -> <TyperGroup >\n  File \"/app/.venv/lib/python3.12/site-packages/click/core.py\", line 1830, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n           |               |       |       |      -> <click.core.Context object at 0x7d08bba89940>\n           |               |       |       -> <function Command.invoke at 0x7d097f93d6c0>\n           |               |       -> <TyperCommand run>\n           |               -> <click.core.Context object at 0x7d08bba89940>\n           -> <function Group.invoke.<locals>._process_result at 0x7d08bbac2b60>\n  File \"/app/.venv/lib/python3.12/site-packages/click/core.py\", line 1226, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n           |   |      |    |           |   -> {'host': '0.0.0.0', 'port': 7860, 'workers': None, 'worker_timeout': None, 'components_path': PosixPath('/app/.venv/lib/pytho...\n           |   |      |    |           -> <click.core.Context object at 0x7d08bba89940>\n           |   |      |    -> <function run at 0x7d08bbac2520>\n           |   |      -> <TyperCommand run>\n           |   -> <function Context.invoke at 0x7d097f93c900>\n           -> <click.core.Context object at 0x7d08bba89940>\n  File \"/app/.venv/lib/python3.12/site-packages/click/core.py\", line 794, in invoke\n    return callback(*args, **kwargs)\n           |         |       -> {'host': '0.0.0.0', 'port': 7860, 'workers': None, 'worker_timeout': None, 'components_path': PosixPath('/app/.venv/lib/pytho...\n           |         -> ()\n           -> <function run at 0x7d08bbac2520>\n  File \"/app/.venv/lib/python3.12/site-packages/typer/main.py\", line 699, in wrapper\n    return callback(**use_params)\n           |          -> {'host': '0.0.0.0', 'workers': None, 'worker_timeout': None, 'port': 7860, 'components_path': PosixPath('/app/.venv/lib/pytho...\n           -> <function run at 0x7d08bbac1800>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/__main__.py\", line 374, in run\n    process_manager.webapp_process.start()\n    |               |              -> <function BaseProcess.start at 0x7d097d1e5620>\n    |               -> <Process name='Process-1' parent=1 started>\n    -> <langflow.__main__.ProcessManager object at 0x7d097f01ebd0>\n  File \"/app/.venv/lib/python3.12/site-packages/multiprocess/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n    |    |        |    |      -> <Process name='Process-1' parent=1 started>\n    |    |        |    -> <staticmethod(<function Process._Popen at 0x7d097d16e480>)>\n    |    |        -> <Process name='Process-1' parent=1 started>\n    |    -> None\n    -> <Process name='Process-1' parent=1 started>\n  File \"/app/.venv/lib/python3.12/site-packages/multiprocess/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n           |                |                            -> <Process name='Process-1' parent=1 started>\n           |                -> <function DefaultContext.get_context at 0x7d097d16e660>\n           -> <multiprocess.context.DefaultContext object at 0x7d097d1edeb0>\n  File \"/app/.venv/lib/python3.12/site-packages/multiprocess/context.py\", line 282, in _Popen\n    return Popen(process_obj)\n           |     -> <Process name='Process-1' parent=1 started>\n           -> <class 'multiprocess.popen_fork.Popen'>\n  File \"/app/.venv/lib/python3.12/site-packages/multiprocess/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n    |    |       -> <Process name='Process-1' parent=1 started>\n    |    -> <function Popen._launch at 0x7d08ba57d760>\n    -> <multiprocess.popen_fork.Popen object at 0x7d08bb22a2d0>\n  File \"/app/.venv/lib/python3.12/site-packages/multiprocess/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n           |           |                          -> 6\n           |           -> <function BaseProcess._bootstrap at 0x7d097d1e6020>\n           -> <Process name='Process-1' parent=1 started>\n  File \"/app/.venv/lib/python3.12/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n    self.run()\n    |    -> <function BaseProcess.run at 0x7d097d1e5580>\n    -> <Process name='Process-1' parent=1 started>\n  File \"/app/.venv/lib/python3.12/site-packages/multiprocess/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n    |    |        |    |        |    -> {}\n    |    |        |    |        -> <Process name='Process-1' parent=1 started>\n    |    |        |    -> ()\n    |    |        -> <Process name='Process-1' parent=1 started>\n    |    -> <bound method BaseApplication.run of <langflow.server.LangflowApplication object at 0x7d08bbace180>>\n    -> <Process name='Process-1' parent=1 started>\n  File \"/app/.venv/lib/python3.12/site-packages/gunicorn/app/base.py\", line 71, in run\n    Arbiter(self).run()\n    |       -> <langflow.server.LangflowApplication object at 0x7d08bbace180>\n    -> <class 'gunicorn.arbiter.Arbiter'>\n  File \"/app/.venv/lib/python3.12/site-packages/gunicorn/arbiter.py\", line 201, in run\n    self.manage_workers()\n    |    -> <function Arbiter.manage_workers at 0x7d08ba70d4e0>\n    -> <gunicorn.arbiter.Arbiter object at 0x7d097d1ed8b0>\n  File \"/app/.venv/lib/python3.12/site-packages/gunicorn/arbiter.py\", line 570, in manage_workers\n    self.spawn_workers()\n    |    -> <function Arbiter.spawn_workers at 0x7d08ba70d620>\n    -> <gunicorn.arbiter.Arbiter object at 0x7d097d1ed8b0>\n  File \"/app/.venv/lib/python3.12/site-packages/gunicorn/arbiter.py\", line 641, in spawn_workers\n    self.spawn_worker()\n    |    -> <function Arbiter.spawn_worker at 0x7d08ba70d580>\n    -> <gunicorn.arbiter.Arbiter object at 0x7d097d1ed8b0>\n  File \"/app/.venv/lib/python3.12/site-packages/gunicorn/arbiter.py\", line 608, in spawn_worker\n    worker.init_process()\n    |      -> <function UvicornWorker.init_process at 0x7d08ba70e480>\n    -> <langflow.server.LangflowUvicornWorker object at 0x7d08ba6decc0>\n  File \"/app/.venv/lib/python3.12/site-packages/uvicorn/workers.py\", line 75, in init_process\n    super().init_process()\n  File \"/app/.venv/lib/python3.12/site-packages/gunicorn/workers/base.py\", line 143, in init_process\n    self.run()\n    |    -> <function UvicornWorker.run at 0x7d08ba56b6a0>\n    -> <langflow.server.LangflowUvicornWorker object at 0x7d08ba6decc0>\n  File \"/app/.venv/lib/python3.12/site-packages/uvicorn/workers.py\", line 107, in run\n    return asyncio.run(self._serve())\n           |       |   |    -> <function LangflowUvicornWorker._serve at 0x7d08ba56b920>\n           |       |   -> <langflow.server.LangflowUvicornWorker object at 0x7d08ba6decc0>\n           |       -> <function run at 0x7d097ee580e0>\n           -> <module 'asyncio' from '/usr/local/lib/python3.12/asyncio/__init__.py'>\n  File \"/usr/local/lib/python3.12/asyncio/runners.py\", line 194, in run\n    return runner.run(main)\n           |      |   -> <coroutine object LangflowUvicornWorker._serve at 0x7d08ba74d3c0>\n           |      -> <function Runner.run at 0x7d097edd9d00>\n           -> <asyncio.runners.Runner object at 0x7d08ba567bf0>\n  File \"/usr/local/lib/python3.12/asyncio/runners.py\", line 118, in run\n    return self._loop.run_until_complete(task)\n           |    |     |                  -> <Task pending name='Task-1' coro=<LangflowUvicornWorker._serve() running at /app/.venv/lib/python3.12/site-packages/langflow/...\n           |    |     -> <function BaseEventLoop.run_until_complete at 0x7d097eddf920>\n           |    -> <_UnixSelectorEventLoop running=True closed=False debug=False>\n           -> <asyncio.runners.Runner object at 0x7d08ba567bf0>\n  File \"/usr/local/lib/python3.12/asyncio/base_events.py\", line 674, in run_until_complete\n    self.run_forever()\n    |    -> <function BaseEventLoop.run_forever at 0x7d097eddf880>\n    -> <_UnixSelectorEventLoop running=True closed=False debug=False>\n  File \"/usr/local/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n    self._run_once()\n    |    -> <function BaseEventLoop._run_once at 0x7d097edd96c0>\n    -> <_UnixSelectorEventLoop running=True closed=False debug=False>\n  File \"/usr/local/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n    handle._run()\n    |      -> <function Handle._run at 0x7d097eeb1800>\n    -> <Handle Task.task_wakeup(<Future finished result=None>)>\n  File \"/usr/local/lib/python3.12/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n    |    |            |    |           |    -> <member '_args' of 'Handle' objects>\n    |    |            |    |           -> <Handle Task.task_wakeup(<Future finished result=None>)>\n    |    |            |    -> <member '_callback' of 'Handle' objects>\n    |    |            -> <Handle Task.task_wakeup(<Future finished result=None>)>\n    |    -> <member '_context' of 'Handle' objects>\n    -> <Handle Task.task_wakeup(<Future finished result=None>)>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/api/build.py\", line 412, in build_vertices\n    vertex_build_response: VertexBuildResponse = await _build_vertex(vertex_id, graph, event_manager)\n                                                       |             |          |      -> <langflow.events.event_manager.EventManager object at 0x7d08bf483aa0>\n                                                       |             |          -> Graph Representation:\n                                                       |             |             ----------------------\n                                                       |             |             Vertices (3):\n                                                       |             |               ChatInput-s5KM6, ChatOutput-Q6jxP, Agent-Ojorb\n                                                       |             |             \n                                                       |             |             Edges (2):\n                                                       |             |               Cha...\n                                                       |             -> 'Agent-Ojorb'\n                                                       -> <function generate_flow_events.<locals>._build_vertex at 0x7d091301df80>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/api/build.py\", line 297, in _build_vertex\n    vertex_build_result = await graph.build_vertex(\n                                |     -> <function Graph.build_vertex at 0x7d09126b0680>\n                                -> Graph Representation:\n                                   ----------------------\n                                   Vertices (3):\n                                     ChatInput-s5KM6, ChatOutput-Q6jxP, Agent-Ojorb\n                                   \n                                   Edges (2):\n                                     Cha...\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/graph/graph/base.py\", line 1458, in build_vertex\n    await vertex.build(\n          |      -> <function Vertex.build at 0x7d091288bba0>\n          -> Vertex(display_name=Agent, id=Agent-Ojorb, data={'id': 'Agent-Ojorb', 'node': {'base_classes': ['Message'], 'beta': False, 'c...\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/graph/vertex/base.py\", line 756, in build\n    await step(user_id=user_id, event_manager=event_manager, **kwargs)\n          |            |                      |                -> {'fallback_to_env_vars': False}\n          |            |                      -> <langflow.events.event_manager.EventManager object at 0x7d08bf483aa0>\n          |            -> '9c027965-2c49-4248-85d1-8d91c0599d2f'\n          -> <bound method Vertex._build of Vertex(display_name=Agent, id=Agent-Ojorb, data={'id': 'Agent-Ojorb', 'node': {'base_classes':...\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/graph/vertex/base.py\", line 398, in _build\n    await self._build_results(\n          |    -> <function Vertex._build_results at 0x7d091288b7e0>\n          -> Vertex(display_name=Agent, id=Agent-Ojorb, data={'id': 'Agent-Ojorb', 'node': {'base_classes': ['Message'], 'beta': False, 'c...\n> File \"/app/.venv/lib/python3.12/site-packages/langflow/graph/vertex/base.py\", line 636, in _build_results\n    result = await initialize.loading.get_instance_results(\n                   |          |       -> <function get_instance_results at 0x7d0912889760>\n                   |          -> <module 'langflow.interface.initialize.loading' from '/app/.venv/lib/python3.12/site-packages/langflow/interface/initialize/l...\n                   -> <module 'langflow.interface.initialize' from '/app/.venv/lib/python3.12/site-packages/langflow/interface/initialize/__init__....\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/interface/initialize/loading.py\", line 72, in get_instance_results\n    return await build_component(params=custom_params, custom_component=custom_component)\n                 |                      |                               -> <langflow.utils.validate.AgentComponent object at 0x7d08bf4811f0>\n                 |                      -> {'add_current_date_tool': True, 'agent_description': 'A helpful assistant with access to the following tools:', 'agent_llm': ...\n                 -> <function build_component at 0x7d0912889a80>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/interface/initialize/loading.py\", line 150, in build_component\n    build_results, artifacts = await custom_component.build_results()\n                                     |                -> <function Component.build_results at 0x7d097bd8ec00>\n                                     -> <langflow.utils.validate.AgentComponent object at 0x7d08bf4811f0>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/custom/custom_component/component.py\", line 1050, in build_results\n    return await self._build_with_tracing()\n                 |    -> <function Component._build_with_tracing at 0x7d097bd8eac0>\n                 -> <langflow.utils.validate.AgentComponent object at 0x7d08bf4811f0>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/custom/custom_component/component.py\", line 1032, in _build_with_tracing\n    results, artifacts = await self._build_results()\n                               |    -> <function Component._build_results at 0x7d097bd8eca0>\n                               -> <langflow.utils.validate.AgentComponent object at 0x7d08bf4811f0>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/custom/custom_component/component.py\", line 1077, in _build_results\n    result = await self._get_output_result(output)\n                   |    |                  -> Output(types=['Message'], selected='Message', name='response', hidden=None, display_name='Response', method='message_response...\n                   |    -> <function Component._get_output_result at 0x7d097bd8efc0>\n                   -> <langflow.utils.validate.AgentComponent object at 0x7d08bf4811f0>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/custom/custom_component/component.py\", line 1152, in _get_output_result\n    result = await method() if inspect.iscoroutinefunction(method) else await asyncio.to_thread(method)\n                   |           |       |                   |                  |       |         -> <bound method AgentComponent.message_response of <langflow.utils.validate.AgentComponent object at 0x7d08bf4811f0>>\n                   |           |       |                   |                  |       -> <function to_thread at 0x7d097ed3e840>\n                   |           |       |                   |                  -> <module 'asyncio' from '/usr/local/lib/python3.12/asyncio/__init__.py'>\n                   |           |       |                   -> <bound method AgentComponent.message_response of <langflow.utils.validate.AgentComponent object at 0x7d08bf4811f0>>\n                   |           |       -> <function iscoroutinefunction at 0x7d097fa1f380>\n                   |           -> <module 'inspect' from '/usr/local/lib/python3.12/inspect.py'>\n                   -> <bound method AgentComponent.message_response of <langflow.utils.validate.AgentComponent object at 0x7d08bf4811f0>>\n  File \"<string>\", line 165, in message_response\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/base/agents/agent.py\", line 177, in run_agent\n    result = await process_agent_events(\n                   -> <function process_agent_events at 0x7d08bb179e40>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/base/agents/events.py\", line 345, in process_agent_events\n    raise ExceptionWithMessageError(agent_message, str(e)) from e\n          |                         -> Message(text_key='text', data={'timestamp': '2025-10-24 11:17:54 UTC', 'sender': 'Machine', 'sender_name': 'Agent', 'session_...\n          -> <class 'langflow.base.agents.events.ExceptionWithMessageError'>\n\nlangflow.base.agents.events.ExceptionWithMessageError: Connection error..\n", "record": {"elapsed": {"repr": "0:09:11.824883", "seconds": 551.824883}, "exception": {"type": "ExceptionWithMessageError", "value": "Connection error..", "traceback": true}, "extra": {}, "file": {"name": "base.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/graph/vertex/base.py"}, "function": "_build_results", "level": {"icon": "❌", "name": "ERROR", "no": 40}, "line": 649, "message": "Connection error..", "module": "base", "name": "langflow.graph.vertex.base", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137479754177408, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:18:08.243215+00:00", "timestamp": 1761304688.243215}}}
{"text": "2025-10-24 11:18:13 - INFO     - build - Task for job_id e73c536d-a0b5-4a9f-9ee6-dd916ba40a7c is already completed\n", "record": {"elapsed": {"repr": "0:09:17.170279", "seconds": 557.170279}, "exception": null, "extra": {}, "file": {"name": "build.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/api/build.py"}, "function": "cancel_flow_build", "level": {"icon": "ℹ️", "name": "INFO", "no": 20}, "line": 506, "message": "Task for job_id e73c536d-a0b5-4a9f-9ee6-dd916ba40a7c is already completed", "module": "build", "name": "langflow.api.build", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137479754177408, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:18:13.588611+00:00", "timestamp": 1761304693.588611}}}
{"text": "2025-10-24 11:18:29 - ERROR    - agent - ExceptionWithMessageError: Connection error..\n", "record": {"elapsed": {"repr": "0:09:33.446644", "seconds": 573.446644}, "exception": null, "extra": {}, "file": {"name": "agent.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/base/agents/agent.py"}, "function": "run_agent", "level": {"icon": "❌", "name": "ERROR", "no": 40}, "line": 191, "message": "ExceptionWithMessageError: Connection error..", "module": "agent", "name": "langflow.base.agents.agent", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137479754177408, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:18:29.864976+00:00", "timestamp": 1761304709.864976}}}
{"text": "2025-10-24 11:18:29 - ERROR    - <string> - ExceptionWithMessageError occurred: Connection error..\n", "record": {"elapsed": {"repr": "0:09:33.447523", "seconds": 573.447523}, "exception": null, "extra": {}, "file": {"name": "<string>", "path": "<string>"}, "function": "message_response", "level": {"icon": "❌", "name": "ERROR", "no": 40}, "line": 171, "message": "ExceptionWithMessageError occurred: Connection error..", "module": "<string>", "name": "langflow.utils.validate", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137479754177408, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:18:29.865855+00:00", "timestamp": 1761304709.865855}}}
{"text": "2025-10-24 11:18:29 - ERROR    - base - Connection error..\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n    yield\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n                 |    |     |                    -> <Request [b'POST']>\n                 |    |     -> <function AsyncConnectionPool.handle_async_request at 0x7d097e18f7e0>\n                 |    -> <AsyncConnectionPool [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>\n                 -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 211, in handle_async_request\n    raise UnsupportedProtocol(\n          -> <class 'httpcore.UnsupportedProtocol'>\n\nhttpcore.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1500, in _request\n    response = await self._client.send(\n                     |    |       -> <function AsyncClient.send at 0x7d097e1bf240>\n                     |    -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n                     -> <openai.AsyncOpenAI object at 0x7d08b84f10a0>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1674, in send\n    response = await self._send_handling_auth(\n                     |    -> <function AsyncClient._send_handling_auth at 0x7d097e1bf2e0>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n    response = await self._send_handling_redirects(\n                     |    -> <function AsyncClient._send_handling_redirects at 0x7d097e1bf380>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n    response = await self._send_single_request(request)\n                     |    |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |    -> <function AsyncClient._send_single_request at 0x7d097e1bf420>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n    response = await transport.handle_async_request(request)\n                     |         |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |         -> <function AsyncHTTPTransport.handle_async_request at 0x7d097e1bc360>\n                     -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 376, in handle_async_request\n    with map_httpcore_exceptions():\n         -> <function map_httpcore_exceptions at 0x7d097ed46520>\n  File \"/usr/local/lib/python3.12/contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n    |    |   |     -> UnsupportedProtocol(\"Request URL has an unsupported protocol 'htp://'.\")\n    |    |   -> <method 'throw' of 'generator' objects>\n    |    -> <generator object map_httpcore_exceptions at 0x7d091892db40>\n    -> <contextlib._GeneratorContextManager object at 0x7d08b851eba0>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\n          |          -> \"Request URL has an unsupported protocol 'htp://'.\"\n          -> <class 'httpx.UnsupportedProtocol'>\n\nhttpx.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n    yield\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n                 |    |     |                    -> <Request [b'POST']>\n                 |    |     -> <function AsyncConnectionPool.handle_async_request at 0x7d097e18f7e0>\n                 |    -> <AsyncConnectionPool [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>\n                 -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 211, in handle_async_request\n    raise UnsupportedProtocol(\n          -> <class 'httpcore.UnsupportedProtocol'>\n\nhttpcore.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1500, in _request\n    response = await self._client.send(\n                     |    |       -> <function AsyncClient.send at 0x7d097e1bf240>\n                     |    -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n                     -> <openai.AsyncOpenAI object at 0x7d08b84f10a0>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1674, in send\n    response = await self._send_handling_auth(\n                     |    -> <function AsyncClient._send_handling_auth at 0x7d097e1bf2e0>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n    response = await self._send_handling_redirects(\n                     |    -> <function AsyncClient._send_handling_redirects at 0x7d097e1bf380>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n    response = await self._send_single_request(request)\n                     |    |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |    -> <function AsyncClient._send_single_request at 0x7d097e1bf420>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n    response = await transport.handle_async_request(request)\n                     |         |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |         -> <function AsyncHTTPTransport.handle_async_request at 0x7d097e1bc360>\n                     -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 376, in handle_async_request\n    with map_httpcore_exceptions():\n         -> <function map_httpcore_exceptions at 0x7d097ed46520>\n  File \"/usr/local/lib/python3.12/contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n    |    |   |     -> UnsupportedProtocol(\"Request URL has an unsupported protocol 'htp://'.\")\n    |    |   -> <method 'throw' of 'generator' objects>\n    |    -> <generator object map_httpcore_exceptions at 0x7d091892e140>\n    -> <contextlib._GeneratorContextManager object at 0x7d091896fdd0>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\n          |          -> \"Request URL has an unsupported protocol 'htp://'.\"\n          -> <class 'httpx.UnsupportedProtocol'>\n\nhttpx.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n    yield\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n                 |    |     |                    -> <Request [b'POST']>\n                 |    |     -> <function AsyncConnectionPool.handle_async_request at 0x7d097e18f7e0>\n                 |    -> <AsyncConnectionPool [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>\n                 -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 211, in handle_async_request\n    raise UnsupportedProtocol(\n          -> <class 'httpcore.UnsupportedProtocol'>\n\nhttpcore.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1500, in _request\n    response = await self._client.send(\n                     |    |       -> <function AsyncClient.send at 0x7d097e1bf240>\n                     |    -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n                     -> <openai.AsyncOpenAI object at 0x7d08b84f10a0>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1674, in send\n    response = await self._send_handling_auth(\n                     |    -> <function AsyncClient._send_handling_auth at 0x7d097e1bf2e0>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n    response = await self._send_handling_redirects(\n                     |    -> <function AsyncClient._send_handling_redirects at 0x7d097e1bf380>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n    response = await self._send_single_request(request)\n                     |    |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |    -> <function AsyncClient._send_single_request at 0x7d097e1bf420>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n    response = await transport.handle_async_request(request)\n                     |         |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |         -> <function AsyncHTTPTransport.handle_async_request at 0x7d097e1bc360>\n                     -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 376, in handle_async_request\n    with map_httpcore_exceptions():\n         -> <function map_httpcore_exceptions at 0x7d097ed46520>\n  File \"/usr/local/lib/python3.12/contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n    |    |   |     -> UnsupportedProtocol(\"Request URL has an unsupported protocol 'htp://'.\")\n    |    |   -> <method 'throw' of 'generator' objects>\n    |    -> <generator object map_httpcore_exceptions at 0x7d091892fa40>\n    -> <contextlib._GeneratorContextManager object at 0x7d0918a9eb10>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\n          |          -> \"Request URL has an unsupported protocol 'htp://'.\"\n          -> <class 'httpx.UnsupportedProtocol'>\n\nhttpx.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n    yield\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n                 |    |     |                    -> <Request [b'POST']>\n                 |    |     -> <function AsyncConnectionPool.handle_async_request at 0x7d097e18f7e0>\n                 |    -> <AsyncConnectionPool [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>\n                 -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 211, in handle_async_request\n    raise UnsupportedProtocol(\n          -> <class 'httpcore.UnsupportedProtocol'>\n\nhttpcore.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1500, in _request\n    response = await self._client.send(\n                     |    |       -> <function AsyncClient.send at 0x7d097e1bf240>\n                     |    -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n                     -> <openai.AsyncOpenAI object at 0x7d08b84f10a0>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1674, in send\n    response = await self._send_handling_auth(\n                     |    -> <function AsyncClient._send_handling_auth at 0x7d097e1bf2e0>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n    response = await self._send_handling_redirects(\n                     |    -> <function AsyncClient._send_handling_redirects at 0x7d097e1bf380>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n    response = await self._send_single_request(request)\n                     |    |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |    -> <function AsyncClient._send_single_request at 0x7d097e1bf420>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n    response = await transport.handle_async_request(request)\n                     |         |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |         -> <function AsyncHTTPTransport.handle_async_request at 0x7d097e1bc360>\n                     -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 376, in handle_async_request\n    with map_httpcore_exceptions():\n         -> <function map_httpcore_exceptions at 0x7d097ed46520>\n  File \"/usr/local/lib/python3.12/contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n    |    |   |     -> UnsupportedProtocol(\"Request URL has an unsupported protocol 'htp://'.\")\n    |    |   -> <method 'throw' of 'generator' objects>\n    |    -> <generator object map_httpcore_exceptions at 0x7d091892f340>\n    -> <contextlib._GeneratorContextManager object at 0x7d0918a9cad0>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\n          |          -> \"Request URL has an unsupported protocol 'htp://'.\"\n          -> <class 'httpx.UnsupportedProtocol'>\n\nhttpx.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n    yield\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n                 |    |     |                    -> <Request [b'POST']>\n                 |    |     -> <function AsyncConnectionPool.handle_async_request at 0x7d097e18f7e0>\n                 |    -> <AsyncConnectionPool [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>\n                 -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 211, in handle_async_request\n    raise UnsupportedProtocol(\n          -> <class 'httpcore.UnsupportedProtocol'>\n\nhttpcore.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1500, in _request\n    response = await self._client.send(\n                     |    |       -> <function AsyncClient.send at 0x7d097e1bf240>\n                     |    -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n                     -> <openai.AsyncOpenAI object at 0x7d08b84f10a0>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1674, in send\n    response = await self._send_handling_auth(\n                     |    -> <function AsyncClient._send_handling_auth at 0x7d097e1bf2e0>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n    response = await self._send_handling_redirects(\n                     |    -> <function AsyncClient._send_handling_redirects at 0x7d097e1bf380>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n    response = await self._send_single_request(request)\n                     |    |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |    -> <function AsyncClient._send_single_request at 0x7d097e1bf420>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n    response = await transport.handle_async_request(request)\n                     |         |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |         -> <function AsyncHTTPTransport.handle_async_request at 0x7d097e1bc360>\n                     -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 376, in handle_async_request\n    with map_httpcore_exceptions():\n         -> <function map_httpcore_exceptions at 0x7d097ed46520>\n  File \"/usr/local/lib/python3.12/contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n    |    |   |     -> UnsupportedProtocol(\"Request URL has an unsupported protocol 'htp://'.\")\n    |    |   -> <method 'throw' of 'generator' objects>\n    |    -> <generator object map_httpcore_exceptions at 0x7d091892e240>\n    -> <contextlib._GeneratorContextManager object at 0x7d0918894440>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\n          |          -> \"Request URL has an unsupported protocol 'htp://'.\"\n          -> <class 'httpx.UnsupportedProtocol'>\n\nhttpx.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n    yield\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n                 |    |     |                    -> <Request [b'POST']>\n                 |    |     -> <function AsyncConnectionPool.handle_async_request at 0x7d097e18f7e0>\n                 |    -> <AsyncConnectionPool [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>\n                 -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 211, in handle_async_request\n    raise UnsupportedProtocol(\n          -> <class 'httpcore.UnsupportedProtocol'>\n\nhttpcore.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1500, in _request\n    response = await self._client.send(\n                     |    |       -> <function AsyncClient.send at 0x7d097e1bf240>\n                     |    -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n                     -> <openai.AsyncOpenAI object at 0x7d08b84f10a0>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1674, in send\n    response = await self._send_handling_auth(\n                     |    -> <function AsyncClient._send_handling_auth at 0x7d097e1bf2e0>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n    response = await self._send_handling_redirects(\n                     |    -> <function AsyncClient._send_handling_redirects at 0x7d097e1bf380>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n    response = await self._send_single_request(request)\n                     |    |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |    -> <function AsyncClient._send_single_request at 0x7d097e1bf420>\n                     -> <langchain_openai.chat_models._client_utils._AsyncHttpxClientWrapper object at 0x7d08b84c7b00>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n    response = await transport.handle_async_request(request)\n                     |         |                    -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n                     |         -> <function AsyncHTTPTransport.handle_async_request at 0x7d097e1bc360>\n                     -> <httpx.AsyncHTTPTransport object at 0x7d08b84c4560>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 376, in handle_async_request\n    with map_httpcore_exceptions():\n         -> <function map_httpcore_exceptions at 0x7d097ed46520>\n  File \"/usr/local/lib/python3.12/contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n    |    |   |     -> UnsupportedProtocol(\"Request URL has an unsupported protocol 'htp://'.\")\n    |    |   -> <method 'throw' of 'generator' objects>\n    |    -> <generator object map_httpcore_exceptions at 0x7d091892ca40>\n    -> <contextlib._GeneratorContextManager object at 0x7d09188959a0>\n  File \"/app/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\n          |          -> \"Request URL has an unsupported protocol 'htp://'.\"\n          -> <class 'httpx.UnsupportedProtocol'>\n\nhttpx.UnsupportedProtocol: Request URL has an unsupported protocol 'htp://'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/base/agents/events.py\", line 334, in process_agent_events\n    async for event in agent_executor:\n              |        -> <async_generator object Runnable.astream_events at 0x7d087056cc40>\n              -> {'event': 'on_chat_model_start', 'data': {'input': {'messages': [[SystemMessage(content='- 사용자의 요청에서 station_id(정수), element(...\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 1404, in astream_events\n    async for event in event_stream:\n              |        -> <async_generator object _astream_events_implementation_v2 at 0x7d08bf43b0b0>\n              -> {'event': 'on_chat_model_start', 'data': {'input': {'messages': [[SystemMessage(content='- 사용자의 요청에서 station_id(정수), element(...\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/tracers/event_stream.py\", line 1021, in _astream_events_implementation_v2\n    await task\n          -> <Task finished name='Task-1805' coro=<_astream_events_implementation_v2.<locals>.consume_astream() done, defined at /app/.ven...\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/tracers/event_stream.py\", line 976, in consume_astream\n    async for _ in event_streamer.tap_output_aiter(run_id, stream):\n                   |              |                |       -> <async_generator object AgentExecutor.astream at 0x7d08b8181240>\n                   |              |                -> UUID('39ea6b3f-cb70-4499-93a5-0b14fad7e23b')\n                   |              -> <function _AstreamEventsCallbackHandler.tap_output_aiter at 0x7d0918a59d00>\n                   -> <langchain_core.tracers.event_stream._AstreamEventsCallbackHandler object at 0x7d091896cd70>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/tracers/event_stream.py\", line 181, in tap_output_aiter\n    first = await py_anext(output, default=sentinel)\n                  |        |               -> <object object at 0x7d0912f719f0>\n                  |        -> <async_generator object AgentExecutor.astream at 0x7d08b8181240>\n                  -> <function py_anext at 0x7d0915b70ae0>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/utils/aiter.py\", line 78, in anext_impl\n    return await __anext__(iterator)\n                 |         -> <async_generator object AgentExecutor.astream at 0x7d08b8181240>\n                 -> <slot wrapper '__anext__' of 'async_generator' objects>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain/agents/agent.py\", line 1805, in astream\n    async for step in iterator:\n                      -> <langchain.agents.agent_iterator.AgentExecutorIterator object at 0x7d091896df10>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain/agents/agent_iterator.py\", line 266, in __aiter__\n    async for chunk in self.agent_executor._aiter_next_step(\n                       |    -> <property object at 0x7d0913ff8900>\n                       -> <langchain.agents.agent_iterator.AgentExecutorIterator object at 0x7d091896df10>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain/agents/agent.py\", line 1495, in _aiter_next_step\n    output = await self._action_agent.aplan(\n                   |    -> <property object at 0x7d0913e977e0>\n                   -> AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n                        agent_scratchpad: RunnableLambd...\n  File \"/app/.venv/lib/python3.12/site-packages/langchain/agents/agent.py\", line 620, in aplan\n    async for chunk in self.runnable.astream(\n                       |    |        -> <function RunnableSequence.astream at 0x7d0915b958a0>\n                       |    -> RunnableAssign(mapper={\n                       |         agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n                       |       })\n                       |       | ChatPro...\n                       -> RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n                            agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['i...\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 3465, in astream\n    async for chunk in self.atransform(input_aiter(), config, **kwargs):\n                       |    |          |              |         -> {}\n                       |    |          |              -> {'callbacks': <langchain_core.callbacks.manager.AsyncCallbackManager object at 0x7d091896f890>}\n                       |    |          -> <function RunnableSequence.astream.<locals>.input_aiter at 0x7d0912eed260>\n                       |    -> <function RunnableSequence.atransform at 0x7d0915b95800>\n                       -> RunnableAssign(mapper={\n                            agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n                          })\n                          | ChatPro...\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 3447, in atransform\n    async for chunk in self._atransform_stream_with_config(\n                       |    -> <function Runnable._atransform_stream_with_config at 0x7d0915b73f60>\n                       -> RunnableAssign(mapper={\n                            agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n                          })\n                          | ChatPro...\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 2322, in _atransform_stream_with_config\n    chunk = await coro_with_context(py_anext(iterator), context)\n                  |                 |        |          -> <_contextvars.Context object at 0x7d08cc26b500>\n                  |                 |        -> <async_generator object _AstreamEventsCallbackHandler.tap_output_aiter at 0x7d08bf5f3cd0>\n                  |                 -> <function py_anext at 0x7d0915b70ae0>\n                  -> <function coro_with_context at 0x7d0915b02f20>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/tracers/event_stream.py\", line 181, in tap_output_aiter\n    first = await py_anext(output, default=sentinel)\n                  |        |               -> <object object at 0x7d08cc30de50>\n                  |        -> <async_generator object RunnableSequence._atransform at 0x7d0918815d00>\n                  -> <function py_anext at 0x7d0915b70ae0>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/utils/aiter.py\", line 78, in anext_impl\n    return await __anext__(iterator)\n                 |         -> <async_generator object RunnableSequence._atransform at 0x7d0918815d00>\n                 -> <slot wrapper '__anext__' of 'async_generator' objects>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 3414, in _atransform\n    async for output in final_pipeline:\n                        -> <async_generator object Runnable.atransform at 0x7d0912fe3340>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 1471, in atransform\n    async for ichunk in input:\n                        -> <async_generator object RunnableBindingBase.atransform at 0x7d091892f540>\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 5660, in atransform\n    async for item in self.bound.atransform(\n                      |    |     -> <function Runnable.atransform at 0x7d0915b736a0>\n                      |    -> ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7d08b84f32f0>, async_client=<openai....\n                      -> RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7d08b84f32f0>,...\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 1489, in atransform\n    async for output in self.astream(final, config, **kwargs):\n                        |    |       |      |         -> {'tools': [{'type': 'function', 'function': {'name': 'get_current_date', 'description': 'Returns the current date and time in...\n                        |    |       |      -> {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.AsyncCallbackManager object at 0x7d08b8539d30>, '...\n                        |    |       -> ChatPromptValue(messages=[SystemMessage(content='- 사용자의 요청에서 station_id(정수), element(대문자 성분), start_time, end_time(YYYY-MM-DD...\n                        |    -> <function BaseChatModel.astream at 0x7d09138bc900>\n                        -> ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7d08b84f32f0>, async_client=<openai....\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 592, in astream\n    async for chunk in self._astream(\n                       |    -> <function ChatOpenAI._astream at 0x7d08bbb15440>\n                       -> ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7d08b84f32f0>, async_client=<openai....\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 2497, in _astream\n    async for chunk in super()._astream(*args, **kwargs):\n                                         |       -> {'stop': None, 'tools': [{'type': 'function', 'function': {'name': 'get_current_date', 'description': 'Returns the current da...\n                                         -> ([SystemMessage(content='- 사용자의 요청에서 station_id(정수), element(대문자 성분), start_time, end_time(YYYY-MM-DD 또는 YYYY-MM-DD HH:MM:SS)...\n  File \"/app/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 1111, in _astream\n    response = await self.async_client.create(**payload)\n                     |    |            |        -> {'model': 'qwen3-30b-awq', 'stream': True, 'seed': 1, 'temperature': 0.1, 'tools': [{'type': 'function', 'function': {'name':...\n                     |    |            -> <function AsyncCompletions.create at 0x7d0910c4b2e0>\n                     |    -> <openai.resources.chat.completions.completions.AsyncCompletions object at 0x7d091896f7d0>\n                     -> ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7d08b84f32f0>, async_client=<openai....\n  File \"/app/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2000, in create\n    return await self._post(\n                 |    -> <bound method AsyncAPIClient.post of <openai.AsyncOpenAI object at 0x7d08b84f10a0>>\n                 -> <openai.resources.chat.completions.completions.AsyncCompletions object at 0x7d091896f7d0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n                 |    |       |        |            |                  -> openai.AsyncStream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]\n                 |    |       |        |            -> True\n                 |    |       |        -> FinalRequestOptions(method='post', url='/chat/completions', params={}, headers=NOT_GIVEN, max_retries=NOT_GIVEN, timeout=NOT_...\n                 |    |       -> <class 'openai.types.chat.chat_completion.ChatCompletion'>\n                 |    -> <function AsyncAPIClient.request at 0x7d0910e9b880>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84f10a0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n                 |    -> <function AsyncAPIClient._request at 0x7d0910e9b920>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84f10a0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1524, in _request\n    return await self._retry_request(\n                 |    -> <function AsyncAPIClient._retry_request at 0x7d0910e9b9c0>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84f10a0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n                 |    -> <function AsyncAPIClient._request at 0x7d0910e9b920>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84f10a0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1524, in _request\n    return await self._retry_request(\n                 |    -> <function AsyncAPIClient._retry_request at 0x7d0910e9b9c0>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84f10a0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n                 |    -> <function AsyncAPIClient._request at 0x7d0910e9b920>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84f10a0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1524, in _request\n    return await self._retry_request(\n                 |    -> <function AsyncAPIClient._retry_request at 0x7d0910e9b9c0>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84f10a0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n                 |    -> <function AsyncAPIClient._request at 0x7d0910e9b920>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84f10a0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1524, in _request\n    return await self._retry_request(\n                 |    -> <function AsyncAPIClient._retry_request at 0x7d0910e9b9c0>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84f10a0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n                 |    -> <function AsyncAPIClient._request at 0x7d0910e9b920>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84f10a0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1524, in _request\n    return await self._retry_request(\n                 |    -> <function AsyncAPIClient._retry_request at 0x7d0910e9b9c0>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84f10a0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n                 |    -> <function AsyncAPIClient._request at 0x7d0910e9b920>\n                 -> <openai.AsyncOpenAI object at 0x7d08b84f10a0>\n  File \"/app/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1534, in _request\n    raise APIConnectionError(request=request) from err\n          |                          -> <Request('POST', 'htp://vllm:8005/v1/chat/completions')>\n          -> <class 'openai.APIConnectionError'>\n\nopenai.APIConnectionError: Connection error.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/app/.venv/bin/langflow\", line 10, in <module>\n    sys.exit(main())\n    |   |    -> <function main at 0x7d097fb2e840>\n    |   -> <built-in function exit>\n    -> <module 'sys' (built-in)>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/langflow_launcher.py\", line 20, in main\n    langflow_main()\n    -> <function main at 0x7d08bbac23e0>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/__main__.py\", line 936, in main\n    app()\n    -> <typer.main.Typer object at 0x7d08bbeaf710>\n  File \"/app/.venv/lib/python3.12/site-packages/typer/main.py\", line 324, in __call__\n    return get_command(self)(*args, **kwargs)\n           |           |      |       -> {}\n           |           |      -> ()\n           |           -> <typer.main.Typer object at 0x7d08bbeaf710>\n           -> <function get_command at 0x7d097efa6840>\n  File \"/app/.venv/lib/python3.12/site-packages/click/core.py\", line 1442, in __call__\n    return self.main(*args, **kwargs)\n           |    |     |       -> {}\n           |    |     -> ()\n           |    -> <function TyperGroup.main at 0x7d097efa51c0>\n           -> <TyperGroup >\n  File \"/app/.venv/lib/python3.12/site-packages/typer/core.py\", line 757, in main\n    return _main(\n           -> <function _main at 0x7d097efa42c0>\n  File \"/app/.venv/lib/python3.12/site-packages/typer/core.py\", line 195, in _main\n    rv = self.invoke(ctx)\n         |    |      -> <click.core.Context object at 0x7d08bbd562a0>\n         |    -> <function Group.invoke at 0x7d097f93e8e0>\n         -> <TyperGroup >\n  File \"/app/.venv/lib/python3.12/site-packages/click/core.py\", line 1830, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n           |               |       |       |      -> <click.core.Context object at 0x7d08bba89940>\n           |               |       |       -> <function Command.invoke at 0x7d097f93d6c0>\n           |               |       -> <TyperCommand run>\n           |               -> <click.core.Context object at 0x7d08bba89940>\n           -> <function Group.invoke.<locals>._process_result at 0x7d08bbac2b60>\n  File \"/app/.venv/lib/python3.12/site-packages/click/core.py\", line 1226, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n           |   |      |    |           |   -> {'host': '0.0.0.0', 'port': 7860, 'workers': None, 'worker_timeout': None, 'components_path': PosixPath('/app/.venv/lib/pytho...\n           |   |      |    |           -> <click.core.Context object at 0x7d08bba89940>\n           |   |      |    -> <function run at 0x7d08bbac2520>\n           |   |      -> <TyperCommand run>\n           |   -> <function Context.invoke at 0x7d097f93c900>\n           -> <click.core.Context object at 0x7d08bba89940>\n  File \"/app/.venv/lib/python3.12/site-packages/click/core.py\", line 794, in invoke\n    return callback(*args, **kwargs)\n           |         |       -> {'host': '0.0.0.0', 'port': 7860, 'workers': None, 'worker_timeout': None, 'components_path': PosixPath('/app/.venv/lib/pytho...\n           |         -> ()\n           -> <function run at 0x7d08bbac2520>\n  File \"/app/.venv/lib/python3.12/site-packages/typer/main.py\", line 699, in wrapper\n    return callback(**use_params)\n           |          -> {'host': '0.0.0.0', 'workers': None, 'worker_timeout': None, 'port': 7860, 'components_path': PosixPath('/app/.venv/lib/pytho...\n           -> <function run at 0x7d08bbac1800>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/__main__.py\", line 374, in run\n    process_manager.webapp_process.start()\n    |               |              -> <function BaseProcess.start at 0x7d097d1e5620>\n    |               -> <Process name='Process-1' parent=1 started>\n    -> <langflow.__main__.ProcessManager object at 0x7d097f01ebd0>\n  File \"/app/.venv/lib/python3.12/site-packages/multiprocess/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n    |    |        |    |      -> <Process name='Process-1' parent=1 started>\n    |    |        |    -> <staticmethod(<function Process._Popen at 0x7d097d16e480>)>\n    |    |        -> <Process name='Process-1' parent=1 started>\n    |    -> None\n    -> <Process name='Process-1' parent=1 started>\n  File \"/app/.venv/lib/python3.12/site-packages/multiprocess/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n           |                |                            -> <Process name='Process-1' parent=1 started>\n           |                -> <function DefaultContext.get_context at 0x7d097d16e660>\n           -> <multiprocess.context.DefaultContext object at 0x7d097d1edeb0>\n  File \"/app/.venv/lib/python3.12/site-packages/multiprocess/context.py\", line 282, in _Popen\n    return Popen(process_obj)\n           |     -> <Process name='Process-1' parent=1 started>\n           -> <class 'multiprocess.popen_fork.Popen'>\n  File \"/app/.venv/lib/python3.12/site-packages/multiprocess/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n    |    |       -> <Process name='Process-1' parent=1 started>\n    |    -> <function Popen._launch at 0x7d08ba57d760>\n    -> <multiprocess.popen_fork.Popen object at 0x7d08bb22a2d0>\n  File \"/app/.venv/lib/python3.12/site-packages/multiprocess/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n           |           |                          -> 6\n           |           -> <function BaseProcess._bootstrap at 0x7d097d1e6020>\n           -> <Process name='Process-1' parent=1 started>\n  File \"/app/.venv/lib/python3.12/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n    self.run()\n    |    -> <function BaseProcess.run at 0x7d097d1e5580>\n    -> <Process name='Process-1' parent=1 started>\n  File \"/app/.venv/lib/python3.12/site-packages/multiprocess/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n    |    |        |    |        |    -> {}\n    |    |        |    |        -> <Process name='Process-1' parent=1 started>\n    |    |        |    -> ()\n    |    |        -> <Process name='Process-1' parent=1 started>\n    |    -> <bound method BaseApplication.run of <langflow.server.LangflowApplication object at 0x7d08bbace180>>\n    -> <Process name='Process-1' parent=1 started>\n  File \"/app/.venv/lib/python3.12/site-packages/gunicorn/app/base.py\", line 71, in run\n    Arbiter(self).run()\n    |       -> <langflow.server.LangflowApplication object at 0x7d08bbace180>\n    -> <class 'gunicorn.arbiter.Arbiter'>\n  File \"/app/.venv/lib/python3.12/site-packages/gunicorn/arbiter.py\", line 201, in run\n    self.manage_workers()\n    |    -> <function Arbiter.manage_workers at 0x7d08ba70d4e0>\n    -> <gunicorn.arbiter.Arbiter object at 0x7d097d1ed8b0>\n  File \"/app/.venv/lib/python3.12/site-packages/gunicorn/arbiter.py\", line 570, in manage_workers\n    self.spawn_workers()\n    |    -> <function Arbiter.spawn_workers at 0x7d08ba70d620>\n    -> <gunicorn.arbiter.Arbiter object at 0x7d097d1ed8b0>\n  File \"/app/.venv/lib/python3.12/site-packages/gunicorn/arbiter.py\", line 641, in spawn_workers\n    self.spawn_worker()\n    |    -> <function Arbiter.spawn_worker at 0x7d08ba70d580>\n    -> <gunicorn.arbiter.Arbiter object at 0x7d097d1ed8b0>\n  File \"/app/.venv/lib/python3.12/site-packages/gunicorn/arbiter.py\", line 608, in spawn_worker\n    worker.init_process()\n    |      -> <function UvicornWorker.init_process at 0x7d08ba70e480>\n    -> <langflow.server.LangflowUvicornWorker object at 0x7d08ba6decc0>\n  File \"/app/.venv/lib/python3.12/site-packages/uvicorn/workers.py\", line 75, in init_process\n    super().init_process()\n  File \"/app/.venv/lib/python3.12/site-packages/gunicorn/workers/base.py\", line 143, in init_process\n    self.run()\n    |    -> <function UvicornWorker.run at 0x7d08ba56b6a0>\n    -> <langflow.server.LangflowUvicornWorker object at 0x7d08ba6decc0>\n  File \"/app/.venv/lib/python3.12/site-packages/uvicorn/workers.py\", line 107, in run\n    return asyncio.run(self._serve())\n           |       |   |    -> <function LangflowUvicornWorker._serve at 0x7d08ba56b920>\n           |       |   -> <langflow.server.LangflowUvicornWorker object at 0x7d08ba6decc0>\n           |       -> <function run at 0x7d097ee580e0>\n           -> <module 'asyncio' from '/usr/local/lib/python3.12/asyncio/__init__.py'>\n  File \"/usr/local/lib/python3.12/asyncio/runners.py\", line 194, in run\n    return runner.run(main)\n           |      |   -> <coroutine object LangflowUvicornWorker._serve at 0x7d08ba74d3c0>\n           |      -> <function Runner.run at 0x7d097edd9d00>\n           -> <asyncio.runners.Runner object at 0x7d08ba567bf0>\n  File \"/usr/local/lib/python3.12/asyncio/runners.py\", line 118, in run\n    return self._loop.run_until_complete(task)\n           |    |     |                  -> <Task pending name='Task-1' coro=<LangflowUvicornWorker._serve() running at /app/.venv/lib/python3.12/site-packages/langflow/...\n           |    |     -> <function BaseEventLoop.run_until_complete at 0x7d097eddf920>\n           |    -> <_UnixSelectorEventLoop running=True closed=False debug=False>\n           -> <asyncio.runners.Runner object at 0x7d08ba567bf0>\n  File \"/usr/local/lib/python3.12/asyncio/base_events.py\", line 674, in run_until_complete\n    self.run_forever()\n    |    -> <function BaseEventLoop.run_forever at 0x7d097eddf880>\n    -> <_UnixSelectorEventLoop running=True closed=False debug=False>\n  File \"/usr/local/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n    self._run_once()\n    |    -> <function BaseEventLoop._run_once at 0x7d097edd96c0>\n    -> <_UnixSelectorEventLoop running=True closed=False debug=False>\n  File \"/usr/local/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n    handle._run()\n    |      -> <function Handle._run at 0x7d097eeb1800>\n    -> <Handle Task.task_wakeup(<Future finished result=None>)>\n  File \"/usr/local/lib/python3.12/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n    |    |            |    |           |    -> <member '_args' of 'Handle' objects>\n    |    |            |    |           -> <Handle Task.task_wakeup(<Future finished result=None>)>\n    |    |            |    -> <member '_callback' of 'Handle' objects>\n    |    |            -> <Handle Task.task_wakeup(<Future finished result=None>)>\n    |    -> <member '_context' of 'Handle' objects>\n    -> <Handle Task.task_wakeup(<Future finished result=None>)>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/api/build.py\", line 412, in build_vertices\n    vertex_build_response: VertexBuildResponse = await _build_vertex(vertex_id, graph, event_manager)\n                                                       |             |          |      -> <langflow.events.event_manager.EventManager object at 0x7d09204d0ec0>\n                                                       |             |          -> Graph Representation:\n                                                       |             |             ----------------------\n                                                       |             |             Vertices (3):\n                                                       |             |               ChatInput-s5KM6, ChatOutput-Q6jxP, Agent-Ojorb\n                                                       |             |             \n                                                       |             |             Edges (2):\n                                                       |             |               Cha...\n                                                       |             -> 'Agent-Ojorb'\n                                                       -> <function generate_flow_events.<locals>._build_vertex at 0x7d091301f2e0>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/api/build.py\", line 297, in _build_vertex\n    vertex_build_result = await graph.build_vertex(\n                                |     -> <function Graph.build_vertex at 0x7d09126b0680>\n                                -> Graph Representation:\n                                   ----------------------\n                                   Vertices (3):\n                                     ChatInput-s5KM6, ChatOutput-Q6jxP, Agent-Ojorb\n                                   \n                                   Edges (2):\n                                     Cha...\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/graph/graph/base.py\", line 1458, in build_vertex\n    await vertex.build(\n          |      -> <function Vertex.build at 0x7d091288bba0>\n          -> Vertex(display_name=Agent, id=Agent-Ojorb, data={'id': 'Agent-Ojorb', 'node': {'base_classes': ['Message'], 'beta': False, 'c...\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/graph/vertex/base.py\", line 756, in build\n    await step(user_id=user_id, event_manager=event_manager, **kwargs)\n          |            |                      |                -> {'fallback_to_env_vars': False}\n          |            |                      -> <langflow.events.event_manager.EventManager object at 0x7d09204d0ec0>\n          |            -> '9c027965-2c49-4248-85d1-8d91c0599d2f'\n          -> <bound method Vertex._build of Vertex(display_name=Agent, id=Agent-Ojorb, data={'id': 'Agent-Ojorb', 'node': {'base_classes':...\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/graph/vertex/base.py\", line 398, in _build\n    await self._build_results(\n          |    -> <function Vertex._build_results at 0x7d091288b7e0>\n          -> Vertex(display_name=Agent, id=Agent-Ojorb, data={'id': 'Agent-Ojorb', 'node': {'base_classes': ['Message'], 'beta': False, 'c...\n> File \"/app/.venv/lib/python3.12/site-packages/langflow/graph/vertex/base.py\", line 636, in _build_results\n    result = await initialize.loading.get_instance_results(\n                   |          |       -> <function get_instance_results at 0x7d0912889760>\n                   |          -> <module 'langflow.interface.initialize.loading' from '/app/.venv/lib/python3.12/site-packages/langflow/interface/initialize/l...\n                   -> <module 'langflow.interface.initialize' from '/app/.venv/lib/python3.12/site-packages/langflow/interface/initialize/__init__....\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/interface/initialize/loading.py\", line 72, in get_instance_results\n    return await build_component(params=custom_params, custom_component=custom_component)\n                 |                      |                               -> <langflow.utils.validate.AgentComponent object at 0x7d0912f82de0>\n                 |                      -> {'add_current_date_tool': True, 'agent_description': 'A helpful assistant with access to the following tools:', 'agent_llm': ...\n                 -> <function build_component at 0x7d0912889a80>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/interface/initialize/loading.py\", line 150, in build_component\n    build_results, artifacts = await custom_component.build_results()\n                                     |                -> <function Component.build_results at 0x7d097bd8ec00>\n                                     -> <langflow.utils.validate.AgentComponent object at 0x7d0912f82de0>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/custom/custom_component/component.py\", line 1050, in build_results\n    return await self._build_with_tracing()\n                 |    -> <function Component._build_with_tracing at 0x7d097bd8eac0>\n                 -> <langflow.utils.validate.AgentComponent object at 0x7d0912f82de0>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/custom/custom_component/component.py\", line 1032, in _build_with_tracing\n    results, artifacts = await self._build_results()\n                               |    -> <function Component._build_results at 0x7d097bd8eca0>\n                               -> <langflow.utils.validate.AgentComponent object at 0x7d0912f82de0>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/custom/custom_component/component.py\", line 1077, in _build_results\n    result = await self._get_output_result(output)\n                   |    |                  -> Output(types=['Message'], selected='Message', name='response', hidden=None, display_name='Response', method='message_response...\n                   |    -> <function Component._get_output_result at 0x7d097bd8efc0>\n                   -> <langflow.utils.validate.AgentComponent object at 0x7d0912f82de0>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/custom/custom_component/component.py\", line 1152, in _get_output_result\n    result = await method() if inspect.iscoroutinefunction(method) else await asyncio.to_thread(method)\n                   |           |       |                   |                  |       |         -> <bound method AgentComponent.message_response of <langflow.utils.validate.AgentComponent object at 0x7d0912f82de0>>\n                   |           |       |                   |                  |       -> <function to_thread at 0x7d097ed3e840>\n                   |           |       |                   |                  -> <module 'asyncio' from '/usr/local/lib/python3.12/asyncio/__init__.py'>\n                   |           |       |                   -> <bound method AgentComponent.message_response of <langflow.utils.validate.AgentComponent object at 0x7d0912f82de0>>\n                   |           |       -> <function iscoroutinefunction at 0x7d097fa1f380>\n                   |           -> <module 'inspect' from '/usr/local/lib/python3.12/inspect.py'>\n                   -> <bound method AgentComponent.message_response of <langflow.utils.validate.AgentComponent object at 0x7d0912f82de0>>\n  File \"<string>\", line 165, in message_response\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/base/agents/agent.py\", line 177, in run_agent\n    result = await process_agent_events(\n                   -> <function process_agent_events at 0x7d08bb179e40>\n  File \"/app/.venv/lib/python3.12/site-packages/langflow/base/agents/events.py\", line 345, in process_agent_events\n    raise ExceptionWithMessageError(agent_message, str(e)) from e\n          |                         -> Message(text_key='text', data={'timestamp': '2025-10-24 11:18:16 UTC', 'sender': 'Machine', 'sender_name': 'Agent', 'session_...\n          -> <class 'langflow.base.agents.events.ExceptionWithMessageError'>\n\nlangflow.base.agents.events.ExceptionWithMessageError: Connection error..\n", "record": {"elapsed": {"repr": "0:09:33.456213", "seconds": 573.456213}, "exception": {"type": "ExceptionWithMessageError", "value": "Connection error..", "traceback": true}, "extra": {}, "file": {"name": "base.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/graph/vertex/base.py"}, "function": "_build_results", "level": {"icon": "❌", "name": "ERROR", "no": 40}, "line": 649, "message": "Connection error..", "module": "base", "name": "langflow.graph.vertex.base", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137479754177408, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:18:29.874545+00:00", "timestamp": 1761304709.874545}}}
{"text": "2025-10-24 11:18:35 - INFO     - build - Task for job_id 3886dff7-2a78-4563-a708-aa39d04b8233 is already completed\n", "record": {"elapsed": {"repr": "0:09:38.634295", "seconds": 578.634295}, "exception": null, "extra": {}, "file": {"name": "build.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/api/build.py"}, "function": "cancel_flow_build", "level": {"icon": "ℹ️", "name": "INFO", "no": 20}, "line": 506, "message": "Task for job_id 3886dff7-2a78-4563-a708-aa39d04b8233 is already completed", "module": "build", "name": "langflow.api.build", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137479754177408, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:18:35.052627+00:00", "timestamp": 1761304715.052627}}}
{"text": "2025-10-24 11:19:25 - ERROR    - build - Build cancelled: \n", "record": {"elapsed": {"repr": "0:10:28.648587", "seconds": 628.648587}, "exception": null, "extra": {}, "file": {"name": "build.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/api/build.py"}, "function": "build_vertices", "level": {"icon": "❌", "name": "ERROR", "no": 40}, "line": 414, "message": "Build cancelled: ", "module": "build", "name": "langflow.api.build", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137479754177408, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:19:25.066919+00:00", "timestamp": 1761304765.066919}}}
{"text": "2025-10-24 11:19:25 - INFO     - build - Task for job_id 52da19f4-f309-4f51-b5d5-a62708b0a7e5 is already completed\n", "record": {"elapsed": {"repr": "0:10:28.653161", "seconds": 628.653161}, "exception": null, "extra": {}, "file": {"name": "build.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/api/build.py"}, "function": "cancel_flow_build", "level": {"icon": "ℹ️", "name": "INFO", "no": 20}, "line": 506, "message": "Task for job_id 52da19f4-f309-4f51-b5d5-a62708b0a7e5 is already completed", "module": "build", "name": "langflow.api.build", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137479754177408, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:19:25.071493+00:00", "timestamp": 1761304765.071493}}}
{"text": "2025-10-24 11:19:34 - INFO     - local - File _mcp_servers.json saved successfully in flow 9c027965-2c49-4248-85d1-8d91c0599d2f.\n", "record": {"elapsed": {"repr": "0:10:37.827371", "seconds": 637.827371}, "exception": null, "extra": {}, "file": {"name": "local.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/services/storage/local.py"}, "function": "save_file", "level": {"icon": "ℹ️", "name": "INFO", "no": 20}, "line": 40, "message": "File _mcp_servers.json saved successfully in flow 9c027965-2c49-4248-85d1-8d91c0599d2f.", "module": "local", "name": "langflow.services.storage.local", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137479754177408, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:19:34.245703+00:00", "timestamp": 1761304774.245703}}}
{"text": "2025-10-24 11:19:43 - WARNING  - local - Attempted to delete non-existent file 9c027965-2c49-4248-85d1-8d91c0599d2f/_mcp_servers.json in flow 9c027965-2c49-4248-85d1-8d91c0599d2f.\n", "record": {"elapsed": {"repr": "0:10:47.392134", "seconds": 647.392134}, "exception": null, "extra": {}, "file": {"name": "local.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/services/storage/local.py"}, "function": "delete_file", "level": {"icon": "⚠️", "name": "WARNING", "no": 30}, "line": 110, "message": "Attempted to delete non-existent file 9c027965-2c49-4248-85d1-8d91c0599d2f/_mcp_servers.json in flow 9c027965-2c49-4248-85d1-8d91c0599d2f.", "module": "local", "name": "langflow.services.storage.local", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137479754177408, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:19:43.810466+00:00", "timestamp": 1761304783.810466}}}
{"text": "2025-10-24 11:19:43 - INFO     - local - File _mcp_servers.json saved successfully in flow 9c027965-2c49-4248-85d1-8d91c0599d2f.\n", "record": {"elapsed": {"repr": "0:10:47.404605", "seconds": 647.404605}, "exception": null, "extra": {}, "file": {"name": "local.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/services/storage/local.py"}, "function": "save_file", "level": {"icon": "ℹ️", "name": "INFO", "no": 20}, "line": 40, "message": "File _mcp_servers.json saved successfully in flow 9c027965-2c49-4248-85d1-8d91c0599d2f.", "module": "local", "name": "langflow.services.storage.local", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137479754177408, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:19:43.822937+00:00", "timestamp": 1761304783.822937}}}
{"text": "2025-10-24 11:19:47 - WARNING  - util - Error checking redirects: \n", "record": {"elapsed": {"repr": "0:10:51.552457", "seconds": 651.552457}, "exception": null, "extra": {}, "file": {"name": "util.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/base/mcp/util.py"}, "function": "pre_check_redirect", "level": {"icon": "⚠️", "name": "WARNING", "no": 30}, "line": 982, "message": "Error checking redirects: ", "module": "util", "name": "langflow.base.mcp.util", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137479754177408, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:19:47.970789+00:00", "timestamp": 1761304787.970789}}}
{"text": "2025-10-24 11:19:47 - INFO     - util - Successfully loaded 3 tools from MCP server 'nier'\n", "record": {"elapsed": {"repr": "0:10:51.578009", "seconds": 651.578009}, "exception": null, "extra": {}, "file": {"name": "util.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/base/mcp/util.py"}, "function": "update_tools", "level": {"icon": "ℹ️", "name": "INFO", "no": 20}, "line": 1255, "message": "Successfully loaded 3 tools from MCP server 'nier'", "module": "util", "name": "langflow.base.mcp.util", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137479754177408, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:19:47.996341+00:00", "timestamp": 1761304787.996341}}}
{"text": "2025-10-24 11:19:48 - WARNING  - util - Error checking redirects: \n", "record": {"elapsed": {"repr": "0:10:52.199399", "seconds": 652.199399}, "exception": null, "extra": {}, "file": {"name": "util.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/base/mcp/util.py"}, "function": "pre_check_redirect", "level": {"icon": "⚠️", "name": "WARNING", "no": 30}, "line": 982, "message": "Error checking redirects: ", "module": "util", "name": "langflow.base.mcp.util", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137479754177408, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:19:48.617731+00:00", "timestamp": 1761304788.617731}}}
{"text": "2025-10-24 11:19:48 - INFO     - util - Successfully loaded 3 tools from MCP server 'nier'\n", "record": {"elapsed": {"repr": "0:10:52.223574", "seconds": 652.223574}, "exception": null, "extra": {}, "file": {"name": "util.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/base/mcp/util.py"}, "function": "update_tools", "level": {"icon": "ℹ️", "name": "INFO", "no": 20}, "line": 1255, "message": "Successfully loaded 3 tools from MCP server 'nier'", "module": "util", "name": "langflow.base.mcp.util", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137479754177408, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:19:48.641906+00:00", "timestamp": 1761304788.641906}}}
{"text": "2025-10-24 11:19:52 - WARNING  - util - Error checking redirects: \n", "record": {"elapsed": {"repr": "0:10:55.624392", "seconds": 655.624392}, "exception": null, "extra": {}, "file": {"name": "util.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/base/mcp/util.py"}, "function": "pre_check_redirect", "level": {"icon": "⚠️", "name": "WARNING", "no": 30}, "line": 982, "message": "Error checking redirects: ", "module": "util", "name": "langflow.base.mcp.util", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137479754177408, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:19:52.042724+00:00", "timestamp": 1761304792.042724}}}
{"text": "2025-10-24 11:19:52 - INFO     - util - Successfully loaded 3 tools from MCP server 'nier'\n", "record": {"elapsed": {"repr": "0:10:55.646954", "seconds": 655.646954}, "exception": null, "extra": {}, "file": {"name": "util.py", "path": "/app/.venv/lib/python3.12/site-packages/langflow/base/mcp/util.py"}, "function": "update_tools", "level": {"icon": "ℹ️", "name": "INFO", "no": 20}, "line": 1255, "message": "Successfully loaded 3 tools from MCP server 'nier'", "module": "util", "name": "langflow.base.mcp.util", "process": {"id": 94, "name": "MainProcess"}, "thread": {"id": 137479754177408, "name": "MainThread"}, "time": {"repr": "2025-10-24 11:19:52.065286+00:00", "timestamp": 1761304792.065286}}}
